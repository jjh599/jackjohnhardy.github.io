{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjh599/jackjohnhardy.github.io/blob/main/OxfordFlowers102CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "egaLH944BBD5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "#device_name = tf.test.gpu_device_name()\n",
        "#if device_name != '/device:GPU:0':\n",
        "#  raise SystemError('GPU device not found')\n",
        "#print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "dataset, dataset_info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True)\n",
        "dataset_info\n",
        "test_set, training_set, validation_set = dataset['test'], dataset['train'], dataset['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8JAGNFt3PGE",
        "outputId": "ae137443-91a8-48ef-b7cc-080b2db43f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physical devices cannot be modified after being initialized\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.experimental.list_physical_devices('GPU')\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "\n",
        "print(gpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgSxJm7OYeKN"
      },
      "source": [
        "Importing TensorFlow "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ql9q6LSWMZRk"
      },
      "outputs": [],
      "source": [
        "num_classes = dataset_info.features['label'].num_classes\n",
        "num_training_examples = 1020\n",
        "num_validation_examples = 1020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xwksk4asQhtr"
      },
      "outputs": [],
      "source": [
        "IMAGE_RES = 256\n",
        "\n",
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "    #label = tf.one_hot(label, depth=num_classes)\n",
        "    return image, label\n",
        "BATCH_SIZE = 8\n",
        "train_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_set.shuffle(num_validation_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = test_set.map(format_image).batch(BATCH_SIZE).prefetch(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9WgfAXPgjFd5"
      },
      "outputs": [],
      "source": [
        "def make_model(input_shape, num_classes):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.RandomFlip(\"horizontal_and_vertical\", input_shape=input_shape))\n",
        "  model.add(layers.RandomRotation(20))\n",
        "  model.add(layers.RandomZoom(0.2))\n",
        "  model.add(layers.RandomContrast(factor=(0.0, 0.1)))\n",
        "  model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1024, activation='relu'))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(num_classes))\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tF9v2wo9F8LW"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pumHmqXelH38",
        "outputId": "2825cc74-73ef-4eda-a9fb-aa6c274c53e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "128/128 [==============================] - 24s 121ms/step - loss: 5.6771 - accuracy: 0.0147 - val_loss: 4.7030 - val_accuracy: 0.0098 - lr: 1.0000e-04\n",
            "Epoch 2/150\n",
            "128/128 [==============================] - 15s 117ms/step - loss: 4.9145 - accuracy: 0.0167 - val_loss: 4.8109 - val_accuracy: 0.0167 - lr: 1.0000e-04\n",
            "Epoch 3/150\n",
            "128/128 [==============================] - 15s 118ms/step - loss: 4.8050 - accuracy: 0.0176 - val_loss: 4.6814 - val_accuracy: 0.0088 - lr: 1.0000e-04\n",
            "Epoch 4/150\n",
            "128/128 [==============================] - 13s 100ms/step - loss: 4.7650 - accuracy: 0.0157 - val_loss: 4.5874 - val_accuracy: 0.0275 - lr: 1.0000e-04\n",
            "Epoch 5/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 4.6904 - accuracy: 0.0118 - val_loss: 4.5062 - val_accuracy: 0.0314 - lr: 1.0000e-04\n",
            "Epoch 6/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 4.6133 - accuracy: 0.0304 - val_loss: 4.4754 - val_accuracy: 0.0353 - lr: 1.0000e-04\n",
            "Epoch 7/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 4.6314 - accuracy: 0.0265 - val_loss: 4.3925 - val_accuracy: 0.0637 - lr: 1.0000e-04\n",
            "Epoch 8/150\n",
            "128/128 [==============================] - 13s 100ms/step - loss: 4.5945 - accuracy: 0.0343 - val_loss: 4.4225 - val_accuracy: 0.0480 - lr: 1.0000e-04\n",
            "Epoch 9/150\n",
            "128/128 [==============================] - 15s 119ms/step - loss: 4.5726 - accuracy: 0.0363 - val_loss: 4.4608 - val_accuracy: 0.0637 - lr: 1.0000e-04\n",
            "Epoch 10/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 4.6492 - accuracy: 0.0225 - val_loss: 4.3799 - val_accuracy: 0.0510 - lr: 1.0000e-04\n",
            "Epoch 11/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 4.5608 - accuracy: 0.0333 - val_loss: 4.2962 - val_accuracy: 0.0725 - lr: 1.0000e-04\n",
            "Epoch 12/150\n",
            "128/128 [==============================] - 13s 100ms/step - loss: 4.4668 - accuracy: 0.0392 - val_loss: 4.1599 - val_accuracy: 0.0863 - lr: 1.0000e-04\n",
            "Epoch 13/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 4.4631 - accuracy: 0.0382 - val_loss: 4.1855 - val_accuracy: 0.0735 - lr: 1.0000e-04\n",
            "Epoch 14/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 4.4401 - accuracy: 0.0471 - val_loss: 4.2553 - val_accuracy: 0.0657 - lr: 1.0000e-04\n",
            "Epoch 15/150\n",
            "128/128 [==============================] - 16s 121ms/step - loss: 4.4775 - accuracy: 0.0451 - val_loss: 4.2111 - val_accuracy: 0.0569 - lr: 1.0000e-04\n",
            "Epoch 16/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 4.3856 - accuracy: 0.0451 - val_loss: 4.0996 - val_accuracy: 0.0824 - lr: 1.0000e-04\n",
            "Epoch 17/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 4.3095 - accuracy: 0.0520 - val_loss: 4.0821 - val_accuracy: 0.0980 - lr: 1.0000e-04\n",
            "Epoch 18/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 4.3670 - accuracy: 0.0588 - val_loss: 4.0504 - val_accuracy: 0.0784 - lr: 1.0000e-04\n",
            "Epoch 19/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 4.3183 - accuracy: 0.0608 - val_loss: 4.0797 - val_accuracy: 0.0902 - lr: 1.0000e-04\n",
            "Epoch 20/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 4.3118 - accuracy: 0.0588 - val_loss: 4.1015 - val_accuracy: 0.0637 - lr: 1.0000e-04\n",
            "Epoch 21/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 4.2219 - accuracy: 0.0637 - val_loss: 3.9250 - val_accuracy: 0.1029 - lr: 1.0000e-04\n",
            "Epoch 22/150\n",
            "128/128 [==============================] - 14s 105ms/step - loss: 4.2211 - accuracy: 0.0647 - val_loss: 3.8854 - val_accuracy: 0.1020 - lr: 1.0000e-04\n",
            "Epoch 23/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 4.1481 - accuracy: 0.0578 - val_loss: 4.0196 - val_accuracy: 0.0873 - lr: 1.0000e-04\n",
            "Epoch 24/150\n",
            "128/128 [==============================] - 16s 121ms/step - loss: 4.1835 - accuracy: 0.0637 - val_loss: 3.8463 - val_accuracy: 0.1137 - lr: 1.0000e-04\n",
            "Epoch 25/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 4.1029 - accuracy: 0.0706 - val_loss: 3.9096 - val_accuracy: 0.1216 - lr: 1.0000e-04\n",
            "Epoch 26/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 3.9827 - accuracy: 0.0794 - val_loss: 3.8016 - val_accuracy: 0.1255 - lr: 1.0000e-04\n",
            "Epoch 27/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 4.0530 - accuracy: 0.0833 - val_loss: 3.8969 - val_accuracy: 0.1098 - lr: 1.0000e-04\n",
            "Epoch 28/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 4.0202 - accuracy: 0.0784 - val_loss: 3.8760 - val_accuracy: 0.1098 - lr: 1.0000e-04\n",
            "Epoch 29/150\n",
            "128/128 [==============================] - 16s 121ms/step - loss: 3.9520 - accuracy: 0.1078 - val_loss: 3.6432 - val_accuracy: 0.1598 - lr: 1.0000e-04\n",
            "Epoch 30/150\n",
            "128/128 [==============================] - 15s 118ms/step - loss: 3.8864 - accuracy: 0.1176 - val_loss: 3.6957 - val_accuracy: 0.1461 - lr: 1.0000e-04\n",
            "Epoch 31/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 3.8065 - accuracy: 0.1147 - val_loss: 3.5167 - val_accuracy: 0.1637 - lr: 1.0000e-04\n",
            "Epoch 32/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 3.8202 - accuracy: 0.1078 - val_loss: 3.5618 - val_accuracy: 0.1667 - lr: 1.0000e-04\n",
            "Epoch 33/150\n",
            "128/128 [==============================] - 16s 121ms/step - loss: 3.8150 - accuracy: 0.1157 - val_loss: 3.9809 - val_accuracy: 0.1578 - lr: 1.0000e-04\n",
            "Epoch 34/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 3.7487 - accuracy: 0.1314 - val_loss: 3.8513 - val_accuracy: 0.1500 - lr: 1.0000e-04\n",
            "Epoch 35/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 3.7489 - accuracy: 0.1245 - val_loss: 3.5546 - val_accuracy: 0.1529 - lr: 1.0000e-04\n",
            "Epoch 36/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 3.7090 - accuracy: 0.1353 - val_loss: 3.7548 - val_accuracy: 0.1422 - lr: 1.0000e-04\n",
            "Epoch 37/150\n",
            "128/128 [==============================] - 13s 100ms/step - loss: 3.6152 - accuracy: 0.1510 - val_loss: 3.3395 - val_accuracy: 0.1961 - lr: 5.0000e-05\n",
            "Epoch 38/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 3.5161 - accuracy: 0.1637 - val_loss: 3.2463 - val_accuracy: 0.2275 - lr: 5.0000e-05\n",
            "Epoch 39/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 3.4243 - accuracy: 0.1745 - val_loss: 3.2221 - val_accuracy: 0.2284 - lr: 5.0000e-05\n",
            "Epoch 40/150\n",
            "128/128 [==============================] - 14s 107ms/step - loss: 3.4478 - accuracy: 0.1647 - val_loss: 3.2815 - val_accuracy: 0.2098 - lr: 5.0000e-05\n",
            "Epoch 41/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 3.3634 - accuracy: 0.1804 - val_loss: 3.2214 - val_accuracy: 0.2196 - lr: 5.0000e-05\n",
            "Epoch 42/150\n",
            "128/128 [==============================] - 16s 121ms/step - loss: 3.3092 - accuracy: 0.2029 - val_loss: 3.1786 - val_accuracy: 0.2333 - lr: 5.0000e-05\n",
            "Epoch 43/150\n",
            "128/128 [==============================] - 15s 119ms/step - loss: 3.2807 - accuracy: 0.1961 - val_loss: 3.2968 - val_accuracy: 0.2206 - lr: 5.0000e-05\n",
            "Epoch 44/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 3.3276 - accuracy: 0.1971 - val_loss: 3.2854 - val_accuracy: 0.2098 - lr: 5.0000e-05\n",
            "Epoch 45/150\n",
            "128/128 [==============================] - 14s 106ms/step - loss: 3.2599 - accuracy: 0.2049 - val_loss: 3.1748 - val_accuracy: 0.2314 - lr: 5.0000e-05\n",
            "Epoch 46/150\n",
            "128/128 [==============================] - 13s 103ms/step - loss: 3.3212 - accuracy: 0.2039 - val_loss: 3.1861 - val_accuracy: 0.2304 - lr: 5.0000e-05\n",
            "Epoch 47/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 3.2171 - accuracy: 0.2245 - val_loss: 3.1336 - val_accuracy: 0.2490 - lr: 5.0000e-05\n",
            "Epoch 48/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 3.2083 - accuracy: 0.2108 - val_loss: 3.1039 - val_accuracy: 0.2510 - lr: 5.0000e-05\n",
            "Epoch 49/150\n",
            "128/128 [==============================] - 16s 118ms/step - loss: 3.2323 - accuracy: 0.2127 - val_loss: 3.0495 - val_accuracy: 0.2696 - lr: 5.0000e-05\n",
            "Epoch 50/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 3.1016 - accuracy: 0.2186 - val_loss: 3.1302 - val_accuracy: 0.2588 - lr: 5.0000e-05\n",
            "Epoch 51/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 3.1157 - accuracy: 0.2235 - val_loss: 3.1389 - val_accuracy: 0.2716 - lr: 5.0000e-05\n",
            "Epoch 52/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 3.1344 - accuracy: 0.2196 - val_loss: 3.0880 - val_accuracy: 0.2647 - lr: 5.0000e-05\n",
            "Epoch 53/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 3.1121 - accuracy: 0.2245 - val_loss: 3.0994 - val_accuracy: 0.2706 - lr: 5.0000e-05\n",
            "Epoch 54/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 3.0725 - accuracy: 0.2422 - val_loss: 3.2292 - val_accuracy: 0.2500 - lr: 5.0000e-05\n",
            "Epoch 55/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 3.0056 - accuracy: 0.2480 - val_loss: 2.9791 - val_accuracy: 0.2667 - lr: 2.5000e-05\n",
            "Epoch 56/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 2.9482 - accuracy: 0.2500 - val_loss: 2.9829 - val_accuracy: 0.2755 - lr: 2.5000e-05\n",
            "Epoch 57/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 2.8433 - accuracy: 0.2676 - val_loss: 2.9384 - val_accuracy: 0.2863 - lr: 2.5000e-05\n",
            "Epoch 58/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 2.8450 - accuracy: 0.2814 - val_loss: 3.0025 - val_accuracy: 0.2588 - lr: 2.5000e-05\n",
            "Epoch 59/150\n",
            "128/128 [==============================] - 14s 105ms/step - loss: 2.7752 - accuracy: 0.2990 - val_loss: 2.9270 - val_accuracy: 0.2833 - lr: 2.5000e-05\n",
            "Epoch 60/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 2.8733 - accuracy: 0.2676 - val_loss: 2.8770 - val_accuracy: 0.2902 - lr: 2.5000e-05\n",
            "Epoch 61/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 2.7618 - accuracy: 0.2873 - val_loss: 2.8896 - val_accuracy: 0.2931 - lr: 2.5000e-05\n",
            "Epoch 62/150\n",
            "128/128 [==============================] - 14s 103ms/step - loss: 2.8335 - accuracy: 0.2873 - val_loss: 2.8374 - val_accuracy: 0.3020 - lr: 2.5000e-05\n",
            "Epoch 63/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 2.7127 - accuracy: 0.3059 - val_loss: 2.9141 - val_accuracy: 0.3000 - lr: 2.5000e-05\n",
            "Epoch 64/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 2.7933 - accuracy: 0.2804 - val_loss: 3.0399 - val_accuracy: 0.2843 - lr: 2.5000e-05\n",
            "Epoch 65/150\n",
            "128/128 [==============================] - 16s 121ms/step - loss: 2.7549 - accuracy: 0.2980 - val_loss: 2.8328 - val_accuracy: 0.3098 - lr: 2.5000e-05\n",
            "Epoch 66/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 2.7343 - accuracy: 0.2676 - val_loss: 2.8930 - val_accuracy: 0.3000 - lr: 2.5000e-05\n",
            "Epoch 67/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 2.7620 - accuracy: 0.2912 - val_loss: 2.8736 - val_accuracy: 0.3020 - lr: 2.5000e-05\n",
            "Epoch 68/150\n",
            "128/128 [==============================] - 16s 122ms/step - loss: 2.6059 - accuracy: 0.3157 - val_loss: 2.8355 - val_accuracy: 0.3059 - lr: 2.5000e-05\n",
            "Epoch 69/150\n",
            "128/128 [==============================] - 14s 107ms/step - loss: 2.6654 - accuracy: 0.3108 - val_loss: 2.8680 - val_accuracy: 0.2971 - lr: 2.5000e-05\n",
            "Epoch 70/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 2.6507 - accuracy: 0.3167 - val_loss: 2.9002 - val_accuracy: 0.3078 - lr: 2.5000e-05\n",
            "Epoch 71/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 2.6278 - accuracy: 0.3235 - val_loss: 2.7608 - val_accuracy: 0.3353 - lr: 1.2500e-05\n",
            "Epoch 72/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 2.6203 - accuracy: 0.3098 - val_loss: 2.7927 - val_accuracy: 0.3137 - lr: 1.2500e-05\n",
            "Epoch 73/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 2.4833 - accuracy: 0.3392 - val_loss: 2.7553 - val_accuracy: 0.3284 - lr: 1.2500e-05\n",
            "Epoch 74/150\n",
            "128/128 [==============================] - 13s 103ms/step - loss: 2.4858 - accuracy: 0.3480 - val_loss: 2.8410 - val_accuracy: 0.3176 - lr: 1.2500e-05\n",
            "Epoch 75/150\n",
            "128/128 [==============================] - 16s 122ms/step - loss: 2.5453 - accuracy: 0.3451 - val_loss: 2.7432 - val_accuracy: 0.3333 - lr: 1.2500e-05\n",
            "Epoch 76/150\n",
            "128/128 [==============================] - 13s 103ms/step - loss: 2.4603 - accuracy: 0.3490 - val_loss: 2.7610 - val_accuracy: 0.3402 - lr: 1.2500e-05\n",
            "Epoch 77/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 2.5138 - accuracy: 0.3529 - val_loss: 2.7418 - val_accuracy: 0.3422 - lr: 1.2500e-05\n",
            "Epoch 78/150\n",
            "128/128 [==============================] - 14s 107ms/step - loss: 2.5089 - accuracy: 0.3510 - val_loss: 2.7759 - val_accuracy: 0.3333 - lr: 1.2500e-05\n",
            "Epoch 79/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 2.3997 - accuracy: 0.3608 - val_loss: 2.7713 - val_accuracy: 0.3324 - lr: 1.2500e-05\n",
            "Epoch 80/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 2.4531 - accuracy: 0.3402 - val_loss: 2.7725 - val_accuracy: 0.3294 - lr: 1.2500e-05\n",
            "Epoch 81/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 2.4561 - accuracy: 0.3529 - val_loss: 2.7795 - val_accuracy: 0.3353 - lr: 1.2500e-05\n",
            "Epoch 82/150\n",
            "128/128 [==============================] - 16s 121ms/step - loss: 2.4180 - accuracy: 0.3539 - val_loss: 2.7664 - val_accuracy: 0.3441 - lr: 1.2500e-05\n",
            "Epoch 83/150\n",
            "128/128 [==============================] - 16s 121ms/step - loss: 2.3882 - accuracy: 0.3618 - val_loss: 2.7463 - val_accuracy: 0.3402 - lr: 6.2500e-06\n",
            "Epoch 84/150\n",
            "128/128 [==============================] - 15s 109ms/step - loss: 2.3117 - accuracy: 0.3716 - val_loss: 2.7230 - val_accuracy: 0.3382 - lr: 6.2500e-06\n",
            "Epoch 85/150\n",
            "128/128 [==============================] - 16s 121ms/step - loss: 2.4302 - accuracy: 0.3539 - val_loss: 2.7166 - val_accuracy: 0.3451 - lr: 6.2500e-06\n",
            "Epoch 86/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 2.3674 - accuracy: 0.3706 - val_loss: 2.6935 - val_accuracy: 0.3451 - lr: 6.2500e-06\n",
            "Epoch 87/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 2.3566 - accuracy: 0.3971 - val_loss: 2.7047 - val_accuracy: 0.3461 - lr: 6.2500e-06\n",
            "Epoch 88/150\n",
            "128/128 [==============================] - 13s 101ms/step - loss: 2.3376 - accuracy: 0.3931 - val_loss: 2.7481 - val_accuracy: 0.3441 - lr: 6.2500e-06\n",
            "Epoch 89/150\n",
            "128/128 [==============================] - 14s 108ms/step - loss: 2.3503 - accuracy: 0.3706 - val_loss: 2.7205 - val_accuracy: 0.3373 - lr: 6.2500e-06\n",
            "Epoch 90/150\n",
            "128/128 [==============================] - 16s 119ms/step - loss: 2.3314 - accuracy: 0.3941 - val_loss: 2.7201 - val_accuracy: 0.3392 - lr: 6.2500e-06\n",
            "Epoch 91/150\n",
            "128/128 [==============================] - 16s 120ms/step - loss: 2.4136 - accuracy: 0.3676 - val_loss: 2.7138 - val_accuracy: 0.3461 - lr: 6.2500e-06\n",
            "Epoch 92/150\n",
            "128/128 [==============================] - 13s 102ms/step - loss: 2.2763 - accuracy: 0.4049 - val_loss: 2.7257 - val_accuracy: 0.3471 - lr: 3.1250e-06\n",
            "Epoch 93/150\n",
            "127/128 [============================>.] - ETA: 0s - loss: 2.3770 - accuracy: 0.3642"
          ]
        }
      ],
      "source": [
        "model = make_model(input_shape=(IMAGE_RES, IMAGE_RES) + (3,), num_classes=102)\n",
        "#keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "epochs = 150\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.000001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_batches,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_batches,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_batch_size=BATCH_SIZE,\n",
        "    verbose=1,\n",
        "    callbacks=[reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('OxfordFlowers102-2.keras')"
      ],
      "metadata": {
        "id": "3tNYk4A0-VT7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4324daheKXsn",
        "outputId": "f4adc96d-90df-4b0d-8f09-a43c29ad8263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "385/385 [==============================] - 14s 36ms/step - loss: 3.2132 - accuracy: 0.3105\n",
            "Test accuracy: 0.3104569911956787\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_batches, verbose=1, batch_size=BATCH_SIZE)\n",
        "print(\"Test accuracy:\", test_acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}