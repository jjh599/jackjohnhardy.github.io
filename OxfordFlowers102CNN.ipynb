{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjh599/jackjohnhardy.github.io/blob/main/OxfordFlowers102CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "egaLH944BBD5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "#device_name = tf.test.gpu_device_name()\n",
        "#if device_name != '/device:GPU:0':\n",
        "#  raise SystemError('GPU device not found')\n",
        "#print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "dataset, dataset_info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True)\n",
        "dataset_info\n",
        "test_set, training_set, validation_set = dataset['test'], dataset['train'], dataset['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8JAGNFt3PGE",
        "outputId": "332ed455-eb38-4f21-9c4e-1a1db58cc098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physical devices cannot be modified after being initialized\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.experimental.list_physical_devices('GPU')\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "\n",
        "print(gpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgSxJm7OYeKN"
      },
      "source": [
        "Importing TensorFlow "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ql9q6LSWMZRk"
      },
      "outputs": [],
      "source": [
        "num_classes = dataset_info.features['label'].num_classes\n",
        "num_training_examples = 1020\n",
        "num_validation_examples = 1020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xwksk4asQhtr"
      },
      "outputs": [],
      "source": [
        "IMAGE_RES = 224\n",
        "\n",
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "    #label = tf.one_hot(label, depth=num_classes)\n",
        "    return image, label\n",
        "BATCH_SIZE = 16\n",
        "train_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_set.shuffle(num_validation_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = test_set.map(format_image).batch(BATCH_SIZE).prefetch(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9WgfAXPgjFd5"
      },
      "outputs": [],
      "source": [
        "def make_model(input_shape, num_classes):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.RandomFlip(\"horizontal_and_vertical\", input_shape=input_shape))\n",
        "  model.add(layers.RandomRotation(20))\n",
        "  model.add(layers.RandomZoom(0.2))\n",
        "  model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1024, activation='relu'))\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  model.add(layers.Dense(num_classes))\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tF9v2wo9F8LW"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pumHmqXelH38",
        "outputId": "bfe0ea13-1d11-4c26-95ba-839ed887b43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "64/64 [==============================] - 27s 195ms/step - loss: 4.9335 - accuracy: 0.0078 - val_loss: 4.6472 - val_accuracy: 0.0098\n",
            "Epoch 2/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 4.6857 - accuracy: 0.0157 - val_loss: 4.6925 - val_accuracy: 0.0098\n",
            "Epoch 3/150\n",
            "64/64 [==============================] - 10s 155ms/step - loss: 4.6254 - accuracy: 0.0235 - val_loss: 4.7217 - val_accuracy: 0.0078\n",
            "Epoch 4/150\n",
            "64/64 [==============================] - 12s 187ms/step - loss: 4.5445 - accuracy: 0.0294 - val_loss: 4.7233 - val_accuracy: 0.0069\n",
            "Epoch 5/150\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 4.4832 - accuracy: 0.0343 - val_loss: 4.7075 - val_accuracy: 0.0098\n",
            "Epoch 6/150\n",
            "64/64 [==============================] - 10s 144ms/step - loss: 4.3984 - accuracy: 0.0490 - val_loss: 4.6405 - val_accuracy: 0.0186\n",
            "Epoch 7/150\n",
            "64/64 [==============================] - 9s 141ms/step - loss: 4.2765 - accuracy: 0.0608 - val_loss: 4.4897 - val_accuracy: 0.0314\n",
            "Epoch 8/150\n",
            "64/64 [==============================] - 10s 148ms/step - loss: 4.2316 - accuracy: 0.0814 - val_loss: 4.2891 - val_accuracy: 0.0716\n",
            "Epoch 9/150\n",
            "64/64 [==============================] - 10s 148ms/step - loss: 4.1066 - accuracy: 0.0784 - val_loss: 4.0685 - val_accuracy: 0.1216\n",
            "Epoch 10/150\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 4.0385 - accuracy: 0.0990 - val_loss: 3.8982 - val_accuracy: 0.1510\n",
            "Epoch 11/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 3.9752 - accuracy: 0.1088 - val_loss: 3.7785 - val_accuracy: 0.1676\n",
            "Epoch 12/150\n",
            "64/64 [==============================] - 10s 141ms/step - loss: 3.8273 - accuracy: 0.1422 - val_loss: 3.6731 - val_accuracy: 0.1980\n",
            "Epoch 13/150\n",
            "64/64 [==============================] - 10s 150ms/step - loss: 3.8058 - accuracy: 0.1451 - val_loss: 3.6842 - val_accuracy: 0.1706\n",
            "Epoch 14/150\n",
            "64/64 [==============================] - 10s 148ms/step - loss: 3.6719 - accuracy: 0.1588 - val_loss: 3.6072 - val_accuracy: 0.1784\n",
            "Epoch 15/150\n",
            "64/64 [==============================] - 10s 154ms/step - loss: 3.5844 - accuracy: 0.1794 - val_loss: 3.5573 - val_accuracy: 0.1912\n",
            "Epoch 16/150\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 3.5007 - accuracy: 0.1814 - val_loss: 3.4991 - val_accuracy: 0.2010\n",
            "Epoch 17/150\n",
            "64/64 [==============================] - 9s 139ms/step - loss: 3.4046 - accuracy: 0.1931 - val_loss: 3.4499 - val_accuracy: 0.2118\n",
            "Epoch 18/150\n",
            "64/64 [==============================] - 9s 142ms/step - loss: 3.4130 - accuracy: 0.1971 - val_loss: 3.4618 - val_accuracy: 0.2147\n",
            "Epoch 19/150\n",
            "64/64 [==============================] - 9s 143ms/step - loss: 3.3197 - accuracy: 0.2206 - val_loss: 3.3803 - val_accuracy: 0.2235\n",
            "Epoch 20/150\n",
            "64/64 [==============================] - 10s 144ms/step - loss: 3.1909 - accuracy: 0.2539 - val_loss: 3.3630 - val_accuracy: 0.2451\n",
            "Epoch 21/150\n",
            "64/64 [==============================] - 9s 139ms/step - loss: 3.1598 - accuracy: 0.2578 - val_loss: 3.2753 - val_accuracy: 0.2431\n",
            "Epoch 22/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 3.0865 - accuracy: 0.2510 - val_loss: 3.3086 - val_accuracy: 0.2392\n",
            "Epoch 23/150\n",
            "64/64 [==============================] - 10s 139ms/step - loss: 3.0375 - accuracy: 0.2765 - val_loss: 3.2342 - val_accuracy: 0.2500\n",
            "Epoch 24/150\n",
            "64/64 [==============================] - 9s 141ms/step - loss: 2.9765 - accuracy: 0.2716 - val_loss: 3.1803 - val_accuracy: 0.2637\n",
            "Epoch 25/150\n",
            "64/64 [==============================] - 10s 148ms/step - loss: 2.9407 - accuracy: 0.3020 - val_loss: 3.1624 - val_accuracy: 0.2588\n",
            "Epoch 26/150\n",
            "64/64 [==============================] - 12s 186ms/step - loss: 2.8823 - accuracy: 0.2892 - val_loss: 3.1064 - val_accuracy: 0.2686\n",
            "Epoch 27/150\n",
            "64/64 [==============================] - 12s 186ms/step - loss: 2.7532 - accuracy: 0.3216 - val_loss: 3.0735 - val_accuracy: 0.2902\n",
            "Epoch 28/150\n",
            "64/64 [==============================] - 10s 150ms/step - loss: 2.7114 - accuracy: 0.3382 - val_loss: 3.1421 - val_accuracy: 0.2863\n",
            "Epoch 29/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 2.7144 - accuracy: 0.3392 - val_loss: 3.1424 - val_accuracy: 0.2775\n",
            "Epoch 30/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 2.6527 - accuracy: 0.3520 - val_loss: 3.0572 - val_accuracy: 0.3010\n",
            "Epoch 31/150\n",
            "64/64 [==============================] - 10s 148ms/step - loss: 2.5907 - accuracy: 0.3510 - val_loss: 3.0716 - val_accuracy: 0.2882\n",
            "Epoch 32/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 2.5641 - accuracy: 0.3500 - val_loss: 3.0306 - val_accuracy: 0.3069\n",
            "Epoch 33/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 2.4465 - accuracy: 0.3902 - val_loss: 3.0051 - val_accuracy: 0.3049\n",
            "Epoch 34/150\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 2.4185 - accuracy: 0.3912 - val_loss: 2.9820 - val_accuracy: 0.3294\n",
            "Epoch 35/150\n",
            "64/64 [==============================] - 9s 143ms/step - loss: 2.4051 - accuracy: 0.3833 - val_loss: 2.9781 - val_accuracy: 0.3196\n",
            "Epoch 36/150\n",
            "64/64 [==============================] - 9s 142ms/step - loss: 2.3329 - accuracy: 0.4127 - val_loss: 2.9761 - val_accuracy: 0.3265\n",
            "Epoch 37/150\n",
            "64/64 [==============================] - 12s 188ms/step - loss: 2.2966 - accuracy: 0.3971 - val_loss: 2.9397 - val_accuracy: 0.3245\n",
            "Epoch 38/150\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 2.2720 - accuracy: 0.4216 - val_loss: 2.9349 - val_accuracy: 0.3304\n",
            "Epoch 39/150\n",
            "64/64 [==============================] - 10s 147ms/step - loss: 2.2054 - accuracy: 0.4245 - val_loss: 2.9042 - val_accuracy: 0.3412\n",
            "Epoch 40/150\n",
            "64/64 [==============================] - 10s 144ms/step - loss: 2.2321 - accuracy: 0.4196 - val_loss: 2.9680 - val_accuracy: 0.3265\n",
            "Epoch 41/150\n",
            "64/64 [==============================] - 10s 150ms/step - loss: 2.1824 - accuracy: 0.4578 - val_loss: 2.9164 - val_accuracy: 0.3451\n",
            "Epoch 42/150\n",
            "64/64 [==============================] - 12s 188ms/step - loss: 2.1326 - accuracy: 0.4382 - val_loss: 2.9157 - val_accuracy: 0.3373\n",
            "Epoch 43/150\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 2.0303 - accuracy: 0.4686 - val_loss: 2.9777 - val_accuracy: 0.3343\n",
            "Epoch 44/150\n",
            "64/64 [==============================] - 9s 141ms/step - loss: 2.0961 - accuracy: 0.4598 - val_loss: 2.8733 - val_accuracy: 0.3608\n",
            "Epoch 45/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 1.9453 - accuracy: 0.4824 - val_loss: 2.8806 - val_accuracy: 0.3627\n",
            "Epoch 46/150\n",
            "64/64 [==============================] - 12s 189ms/step - loss: 1.9503 - accuracy: 0.4951 - val_loss: 2.9470 - val_accuracy: 0.3520\n",
            "Epoch 47/150\n",
            "64/64 [==============================] - 10s 152ms/step - loss: 1.9577 - accuracy: 0.4833 - val_loss: 2.9367 - val_accuracy: 0.3461\n",
            "Epoch 48/150\n",
            "64/64 [==============================] - 9s 141ms/step - loss: 1.9516 - accuracy: 0.4843 - val_loss: 2.8956 - val_accuracy: 0.3578\n",
            "Epoch 49/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 1.9069 - accuracy: 0.4843 - val_loss: 2.8676 - val_accuracy: 0.3637\n",
            "Epoch 50/150\n",
            "64/64 [==============================] - 9s 142ms/step - loss: 1.8591 - accuracy: 0.5020 - val_loss: 2.9780 - val_accuracy: 0.3353\n",
            "Epoch 51/150\n",
            "64/64 [==============================] - 10s 147ms/step - loss: 1.8070 - accuracy: 0.5235 - val_loss: 2.8687 - val_accuracy: 0.3627\n",
            "Epoch 52/150\n",
            "64/64 [==============================] - 12s 186ms/step - loss: 1.8073 - accuracy: 0.5167 - val_loss: 2.9000 - val_accuracy: 0.3500\n",
            "Epoch 53/150\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-992c8438b025>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = make_model(input_shape=(IMAGE_RES, IMAGE_RES) + (3,), num_classes=102)\n",
        "#keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "epochs = 150\n",
        "\n",
        "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_batches,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_batches,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_batch_size=BATCH_SIZE,\n",
        "    verbose=1\n",
        "    #callbacks=[reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('OxfordFlowers102-2.keras')"
      ],
      "metadata": {
        "id": "3tNYk4A0-VT7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4324daheKXsn",
        "outputId": "00053ba7-9e3e-46ae-dff8-c0f10b5dc625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "193/193 [==============================] - 14s 70ms/step - loss: 3.7169 - accuracy: 0.2558\n",
            "Test accuracy: 0.25581395626068115\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_batches, verbose=1, batch_size=BATCH_SIZE)\n",
        "print(\"Test accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5mwAYWdP405",
        "outputId": "ede4f831-861e-47c7-8bd9-654ed965d7aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(32, 224, 224, 3), dtype=float32, numpy=\n",
            "array([[[[2.20325626e-02, 3.77188362e-02, 3.37972678e-02],\n",
            "         [2.20325626e-02, 3.77188362e-02, 3.37972678e-02],\n",
            "         [2.20325626e-02, 3.77188362e-02, 3.37972678e-02],\n",
            "         ...,\n",
            "         [2.94296108e-02, 2.94296108e-02, 2.94296108e-02],\n",
            "         [2.35294122e-02, 2.35294122e-02, 2.35294122e-02],\n",
            "         [2.35294122e-02, 2.35294122e-02, 2.35294122e-02]],\n",
            "\n",
            "        [[2.35294122e-02, 3.92156877e-02, 3.52941193e-02],\n",
            "         [2.35294122e-02, 3.92156877e-02, 3.52941193e-02],\n",
            "         [2.35294122e-02, 3.92156877e-02, 3.52941193e-02],\n",
            "         ...,\n",
            "         [2.63661519e-02, 2.63661519e-02, 2.63661519e-02],\n",
            "         [2.35294122e-02, 2.35294122e-02, 2.35294122e-02],\n",
            "         [2.35294122e-02, 2.35294122e-02, 2.35294122e-02]],\n",
            "\n",
            "        [[2.74509806e-02, 4.31372561e-02, 3.92156877e-02],\n",
            "         [2.74509806e-02, 4.31372561e-02, 3.92156877e-02],\n",
            "         [2.74509806e-02, 4.31372561e-02, 3.92156877e-02],\n",
            "         ...,\n",
            "         [2.10521016e-02, 2.10521016e-02, 2.10521016e-02],\n",
            "         [2.35294122e-02, 2.35294122e-02, 2.35294122e-02],\n",
            "         [2.35294122e-02, 2.35294122e-02, 2.35294122e-02]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[3.24315280e-02, 3.99421901e-02, 1.10258732e-03],\n",
            "         [3.72822061e-02, 3.81488055e-02, 2.82650739e-02],\n",
            "         [4.55706716e-02, 4.16491032e-02, 6.43198192e-02],\n",
            "         ...,\n",
            "         [2.74509806e-02, 2.74509806e-02, 2.74509806e-02],\n",
            "         [2.74509806e-02, 2.74509806e-02, 2.74509806e-02],\n",
            "         [2.74509806e-02, 2.74509806e-02, 2.74509806e-02]],\n",
            "\n",
            "        [[5.24402671e-02, 6.02834038e-02, 1.71461478e-02],\n",
            "         [5.64632267e-02, 6.34397715e-02, 4.12321351e-02],\n",
            "         [4.45815809e-02, 5.24247177e-02, 4.06600125e-02],\n",
            "         ...,\n",
            "         [2.35372707e-02, 2.35372707e-02, 2.35372707e-02],\n",
            "         [2.61027012e-02, 2.61027012e-02, 2.61027012e-02],\n",
            "         [2.91158967e-02, 2.91158967e-02, 2.91158967e-02]],\n",
            "\n",
            "        [[8.14249665e-02, 8.92681032e-02, 4.61308509e-02],\n",
            "         [6.48090541e-02, 7.17855915e-02, 4.95779663e-02],\n",
            "         [5.09454682e-02, 5.87886050e-02, 4.70238999e-02],\n",
            "         ...,\n",
            "         [3.08907498e-02, 3.08907498e-02, 3.08907498e-02],\n",
            "         [5.45408204e-02, 5.45408204e-02, 5.45408204e-02],\n",
            "         [6.14179559e-02, 6.14179559e-02, 6.14179559e-02]]],\n",
            "\n",
            "\n",
            "       [[[9.36449587e-01, 9.98792052e-01, 9.60784316e-01],\n",
            "         [8.93207252e-01, 9.52030778e-01, 9.32422936e-01],\n",
            "         [8.57075453e-01, 9.13885713e-01, 9.08160925e-01],\n",
            "         ...,\n",
            "         [3.49944085e-01, 2.39618197e-01, 2.82834470e-01],\n",
            "         [3.86712015e-01, 2.73284048e-01, 3.33315581e-01],\n",
            "         [5.00625432e-01, 4.28023070e-01, 4.90768164e-01]],\n",
            "\n",
            "        [[9.40371156e-01, 9.99194682e-01, 9.71743703e-01],\n",
            "         [8.91386509e-01, 9.50210035e-01, 9.30602193e-01],\n",
            "         [8.31546068e-01, 8.90369594e-01, 8.74788344e-01],\n",
            "         ...,\n",
            "         [3.61485988e-01, 2.51892686e-01, 2.92911172e-01],\n",
            "         [3.57554585e-01, 2.44126618e-01, 3.03133518e-01],\n",
            "         [4.55378890e-01, 3.82776499e-01, 4.45521593e-01]],\n",
            "\n",
            "        [[9.35504198e-01, 9.94958043e-01, 9.67191875e-01],\n",
            "         [8.74457240e-01, 9.33911085e-01, 9.13988054e-01],\n",
            "         [7.94607818e-01, 8.54061604e-01, 8.37841749e-01],\n",
            "         ...,\n",
            "         [3.77052814e-01, 2.65446097e-01, 3.05834323e-01],\n",
            "         [3.44862372e-01, 2.40485564e-01, 2.92673945e-01],\n",
            "         [4.04127538e-01, 3.31992716e-01, 3.86459470e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[4.36942488e-01, 5.42422116e-01, 2.42072016e-01],\n",
            "         [3.85189116e-01, 4.82020319e-01, 2.28028744e-01],\n",
            "         [3.92471969e-01, 4.70903337e-01, 2.67086834e-01],\n",
            "         ...,\n",
            "         [5.04434228e-01, 2.76877910e-01, 3.53401154e-01],\n",
            "         [3.87990564e-01, 1.93715170e-01, 2.58876294e-01],\n",
            "         [3.27920526e-01, 1.62408993e-01, 2.17713773e-01]],\n",
            "\n",
            "        [[4.50306565e-01, 5.46874821e-01, 2.31652960e-01],\n",
            "         [4.09348726e-01, 5.07799864e-01, 2.43338063e-01],\n",
            "         [4.11974788e-01, 5.02170861e-01, 2.90616244e-01],\n",
            "         ...,\n",
            "         [4.58972126e-01, 2.25375518e-01, 3.03912193e-01],\n",
            "         [3.57562184e-01, 1.73276141e-01, 2.35609353e-01],\n",
            "         [3.40520054e-01, 1.91543639e-01, 2.42331594e-01]],\n",
            "\n",
            "        [[4.53291327e-01, 5.43890059e-01, 2.30969876e-01],\n",
            "         [4.09348726e-01, 5.10101557e-01, 2.37710088e-01],\n",
            "         [4.11974788e-01, 5.02170861e-01, 2.90616244e-01],\n",
            "         ...,\n",
            "         [4.26769048e-01, 1.93172440e-01, 2.71709114e-01],\n",
            "         [3.40283811e-01, 1.62902713e-01, 2.22934261e-01],\n",
            "         [3.38203073e-01, 1.96220919e-01, 2.43682578e-01]]],\n",
            "\n",
            "\n",
            "       [[[3.05882365e-01, 2.90196091e-01, 2.93469906e-01],\n",
            "         [2.88725495e-01, 2.69117653e-01, 2.57352948e-01],\n",
            "         [2.49842674e-01, 2.16850728e-01, 2.01847225e-01],\n",
            "         ...,\n",
            "         [3.88007581e-01, 3.68399739e-01, 3.56635034e-01],\n",
            "         [4.16788399e-01, 3.88331175e-01, 3.75967801e-01],\n",
            "         [4.43084806e-01, 4.11712259e-01, 3.99947554e-01]],\n",
            "\n",
            "        [[3.06752324e-01, 2.91066051e-01, 2.87144482e-01],\n",
            "         [2.97478974e-01, 2.77871132e-01, 2.66106427e-01],\n",
            "         [2.65309870e-01, 2.27618024e-01, 2.10082635e-01],\n",
            "         ...,\n",
            "         [3.79963189e-01, 3.48590612e-01, 3.36825907e-01],\n",
            "         [3.85951936e-01, 3.63428771e-01, 3.43710154e-01],\n",
            "         [4.05654818e-01, 3.86046976e-01, 3.62517565e-01]],\n",
            "\n",
            "        [[2.98371822e-01, 2.81774729e-01, 2.77520746e-01],\n",
            "         [3.06573868e-01, 2.75201321e-01, 2.66386539e-01],\n",
            "         [2.82613218e-01, 2.44080290e-01, 2.22853065e-01],\n",
            "         ...,\n",
            "         [3.50682914e-01, 3.19362760e-01, 2.97137648e-01],\n",
            "         [3.47839952e-01, 3.25658321e-01, 3.01576734e-01],\n",
            "         [3.70325685e-01, 3.51033002e-01, 3.26558203e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.43565774e-01, 2.69055992e-01, 8.47422406e-02],\n",
            "         [1.39730766e-01, 2.61299402e-01, 8.87503698e-02],\n",
            "         [1.34016111e-01, 2.55584747e-01, 9.24982503e-02],\n",
            "         ...,\n",
            "         [1.43266261e-01, 5.21333590e-02, 1.47442028e-01],\n",
            "         [5.73167913e-02, 3.89667451e-02, 5.76928146e-02],\n",
            "         [3.19767445e-02, 3.91896628e-02, 3.55832055e-02]],\n",
            "\n",
            "        [[1.56862751e-01, 2.85626769e-01, 1.11220017e-01],\n",
            "         [1.50997892e-01, 2.60801822e-01, 1.01436928e-01],\n",
            "         [1.39557078e-01, 2.47392133e-01, 1.04770727e-01],\n",
            "         ...,\n",
            "         [2.18345687e-01, 1.24664851e-01, 1.12606511e-01],\n",
            "         [1.49812609e-01, 9.52135772e-02, 3.24103534e-02],\n",
            "         [1.16227962e-01, 7.50789866e-02, 2.45501045e-02]],\n",
            "\n",
            "        [[1.58244058e-01, 2.87008077e-01, 1.18704475e-01],\n",
            "         [1.50997892e-01, 2.60801822e-01, 1.03939071e-01],\n",
            "         [1.36633158e-01, 2.42515504e-01, 1.08499393e-01],\n",
            "         ...,\n",
            "         [3.28798234e-01, 2.33743772e-01, 1.95290655e-01],\n",
            "         [2.90020019e-01, 2.23227039e-01, 1.14367843e-01],\n",
            "         [2.56310195e-01, 1.97997928e-01, 9.66356620e-02]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[7.70308077e-02, 8.48739445e-02, 3.06722671e-02],\n",
            "         [1.79259218e-02, 2.18474921e-02, 0.00000000e+00],\n",
            "         [3.22966725e-02, 3.62182409e-02, 1.66103970e-02],\n",
            "         ...,\n",
            "         [3.57695073e-01, 1.53675914e-01, 7.27452636e-02],\n",
            "         [3.21809828e-01, 1.25770241e-01, 7.08682761e-02],\n",
            "         [2.86437929e-01, 9.28331017e-02, 5.49019612e-02]],\n",
            "\n",
            "        [[7.38095194e-02, 8.16526636e-02, 2.74509806e-02],\n",
            "         [1.72268916e-02, 2.11484618e-02, 0.00000000e+00],\n",
            "         [2.76260525e-02, 3.15476209e-02, 1.19397771e-02],\n",
            "         ...,\n",
            "         [3.84593427e-01, 1.70629069e-01, 8.88240263e-02],\n",
            "         [3.38682830e-01, 1.32979318e-01, 7.45134875e-02],\n",
            "         [3.01575273e-01, 9.89504680e-02, 4.88417447e-02]],\n",
            "\n",
            "        [[6.98316842e-02, 7.76748210e-02, 2.34731399e-02],\n",
            "         [1.33053241e-02, 1.72268916e-02, 0.00000000e+00],\n",
            "         [1.97128821e-02, 2.36344505e-02, 4.02660761e-03],\n",
            "         ...,\n",
            "         [4.02942002e-01, 1.75491035e-01, 8.94268677e-02],\n",
            "         [3.55322033e-01, 1.37814984e-01, 6.48459047e-02],\n",
            "         [3.29341918e-01, 1.22016512e-01, 6.62254244e-02]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[4.84593846e-02, 7.55952597e-02, 1.34803755e-02],\n",
            "         [6.90826103e-02, 9.62184817e-02, 3.41036059e-02],\n",
            "         [6.77170530e-02, 9.48529243e-02, 3.27380411e-02],\n",
            "         ...,\n",
            "         [1.00739770e-01, 1.16459817e-01, 2.39185300e-02],\n",
            "         [1.64652213e-01, 1.84406355e-01, 6.24875575e-02],\n",
            "         [1.40699178e-01, 1.60622135e-01, 3.45017314e-02]],\n",
            "\n",
            "        [[6.39343560e-02, 7.72421136e-02, 2.35294122e-02],\n",
            "         [5.49407490e-02, 6.63477704e-02, 1.35854343e-02],\n",
            "         [4.71226051e-02, 5.56785129e-02, 4.34173504e-03],\n",
            "         ...,\n",
            "         [3.87104936e-02, 4.60221581e-02, 3.40980641e-03],\n",
            "         [1.66277885e-01, 1.83466032e-01, 8.11623931e-02],\n",
            "         [1.52204201e-01, 1.79061353e-01, 1.85915474e-02]],\n",
            "\n",
            "        [[6.66666701e-02, 7.45098069e-02, 2.35294122e-02],\n",
            "         [5.67226894e-02, 6.45658299e-02, 1.35854343e-02],\n",
            "         [4.74789888e-02, 5.53221256e-02, 4.34173504e-03],\n",
            "         ...,\n",
            "         [2.21993234e-02, 2.65411977e-02, 2.58932298e-04],\n",
            "         [1.44292980e-01, 1.59699202e-01, 6.09594025e-02],\n",
            "         [1.65405989e-01, 1.92856967e-01, 2.24082805e-02]]],\n",
            "\n",
            "\n",
            "       [[[4.44068154e-03, 7.71708637e-02, 3.96564777e-04],\n",
            "         [1.75077841e-02, 9.20175910e-02, 5.74307842e-03],\n",
            "         [1.30077023e-02, 8.75174999e-02, 1.30077023e-02],\n",
            "         ...,\n",
            "         [5.51643595e-02, 1.80462599e-01, 4.91861887e-02],\n",
            "         [4.27337065e-02, 1.06932394e-01, 3.40679102e-02],\n",
            "         [2.21464951e-02, 7.70484582e-02, 1.03817889e-02]],\n",
            "\n",
            "        [[1.34621039e-02, 8.75334516e-02, 1.08551253e-02],\n",
            "         [2.60329116e-02, 1.00542717e-01, 2.54376754e-02],\n",
            "         [2.06368510e-02, 9.51466560e-02, 2.06368510e-02],\n",
            "         ...,\n",
            "         [3.75390984e-02, 1.55130163e-01, 3.13456953e-02],\n",
            "         [2.07983181e-02, 9.36628059e-02, 1.68767497e-02],\n",
            "         [9.31462273e-03, 7.59812891e-02, 5.39305434e-03]],\n",
            "\n",
            "        [[1.98004171e-02, 9.03886557e-02, 2.82738097e-02],\n",
            "         [2.84973159e-03, 7.33057261e-02, 1.06928684e-02],\n",
            "         [2.39372347e-02, 9.84470397e-02, 2.39372347e-02],\n",
            "         ...,\n",
            "         [7.23614730e-03, 1.23232812e-01, 9.69928689e-03],\n",
            "         [5.18565020e-03, 8.88753757e-02, 8.66579544e-03],\n",
            "         [8.79317336e-03, 8.39332342e-02, 9.42342915e-03]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.52005814e-02, 2.20108051e-02, 0.00000000e+00],\n",
            "         [8.22830189e-04, 1.79621819e-02, 3.09873838e-03],\n",
            "         [2.28623697e-03, 2.70658229e-02, 1.49788307e-02],\n",
            "         ...,\n",
            "         [1.69294775e-02, 1.14653580e-01, 2.83790734e-02],\n",
            "         [1.59448180e-02, 1.31183416e-01, 1.89776253e-02],\n",
            "         [5.22056445e-02, 1.73144057e-01, 5.18905334e-02]],\n",
            "\n",
            "        [[1.66650526e-02, 2.82738097e-02, 3.64071829e-03],\n",
            "         [1.17647061e-02, 1.17647061e-02, 1.03688473e-02],\n",
            "         [2.24789940e-02, 3.40511203e-02, 2.31013838e-02],\n",
            "         ...,\n",
            "         [1.15759941e-02, 1.31279379e-01, 2.10898230e-03],\n",
            "         [3.07996422e-02, 1.56247437e-01, 2.16210466e-02],\n",
            "         [4.64635529e-02, 1.79796889e-01, 4.74421009e-02]],\n",
            "\n",
            "        [[1.17647061e-02, 2.82738097e-02, 7.84313772e-03],\n",
            "         [1.17647061e-02, 1.17647061e-02, 1.17647061e-02],\n",
            "         [1.72663517e-02, 2.88384799e-02, 1.33447843e-02],\n",
            "         ...,\n",
            "         [9.82932001e-03, 1.34076312e-01, 0.00000000e+00],\n",
            "         [5.24497330e-02, 1.85783073e-01, 4.85281609e-02],\n",
            "         [2.97909230e-02, 1.63124248e-01, 2.58693546e-02]]],\n",
            "\n",
            "\n",
            "       [[[7.00455189e-01, 4.49474812e-01, 7.50579119e-01],\n",
            "         [7.05831945e-01, 4.67364818e-01, 7.46634066e-01],\n",
            "         [7.13725507e-01, 5.01523077e-01, 7.37641752e-01],\n",
            "         ...,\n",
            "         [3.37122381e-01, 2.54225016e-01, 2.69217581e-01],\n",
            "         [2.06544802e-01, 1.22555107e-01, 2.03662336e-01],\n",
            "         [5.00716984e-01, 3.93170655e-01, 5.38182735e-01]],\n",
            "\n",
            "        [[7.13160753e-01, 4.72085088e-01, 7.49026239e-01],\n",
            "         [7.16920555e-01, 4.85508114e-01, 7.45561957e-01],\n",
            "         [7.17832685e-01, 5.15423715e-01, 7.36692905e-01],\n",
            "         ...,\n",
            "         [1.51119262e-01, 1.36991173e-01, 8.45854282e-02],\n",
            "         [1.34459630e-01, 7.47785196e-02, 9.16081443e-02],\n",
            "         [4.20208067e-01, 3.21442187e-01, 4.08644617e-01]],\n",
            "\n",
            "        [[7.30082273e-01, 5.02550781e-01, 7.40861356e-01],\n",
            "         [7.25684583e-01, 5.10302901e-01, 7.32409060e-01],\n",
            "         [7.25805283e-01, 5.37447512e-01, 7.25078762e-01],\n",
            "         ...,\n",
            "         [7.52025694e-02, 1.12615362e-01, 8.89464654e-03],\n",
            "         [2.64672190e-01, 2.03638390e-01, 1.84644118e-01],\n",
            "         [4.25364316e-01, 3.05826515e-01, 3.45122755e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.97298616e-01, 4.75227565e-01, 1.00208245e-01],\n",
            "         [2.31115296e-01, 4.02799219e-01, 1.30351901e-01],\n",
            "         [3.14040869e-01, 3.46122414e-01, 2.20553443e-01],\n",
            "         ...,\n",
            "         [9.36976895e-02, 1.10644400e-01, 5.18208668e-02],\n",
            "         [6.68611452e-02, 9.58138183e-02, 3.29480954e-02],\n",
            "         [5.91386370e-02, 1.02946401e-01, 3.61588784e-02]],\n",
            "\n",
            "        [[2.16251060e-01, 4.25665170e-01, 8.91063511e-02],\n",
            "         [2.27803573e-01, 4.00969267e-01, 4.70245108e-02],\n",
            "         [2.76213080e-01, 3.67929101e-01, 1.03509873e-01],\n",
            "         ...,\n",
            "         [3.99686918e-02, 9.15443599e-02, 2.48776898e-02],\n",
            "         [2.85103600e-02, 7.28381574e-02, 9.38653294e-03],\n",
            "         [3.52941193e-02, 7.96086192e-02, 1.29486015e-02]],\n",
            "\n",
            "        [[2.12674960e-01, 4.08709615e-01, 7.55513683e-02],\n",
            "         [2.31059536e-01, 4.04002458e-01, 2.40042079e-02],\n",
            "         [2.79061675e-01, 3.90178621e-01, 8.60294551e-02],\n",
            "         ...,\n",
            "         [6.53188676e-02, 1.20220825e-01, 5.35541624e-02],\n",
            "         [5.00701293e-02, 1.01050526e-01, 3.43838558e-02],\n",
            "         [4.46429066e-02, 9.55356956e-02, 2.89128330e-02]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32, 102), dtype=float32, numpy=\n",
            "array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>)\n"
          ]
        }
      ],
      "source": [
        "for features in train_batches.take(1):\n",
        "  print(features)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}